{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting R Companion html and converting to markdown text\n",
    "\n",
    "Meant to be run in sessions launched from [here](https://github.com/fomightez/rcomp_testenv). (This can also be run [here](https://github.com/fomightez/muscle-binder) where I added the recent version of pandoc on Feb 3, 2019.) That version added conversion to markdown.\n",
    "\n",
    "This is based on approach worked out in `developing automating getting circos html and converting to markdown text.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_companion_index_url = \"https://rcompanion.org/rcompanion/index.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_prefix = \"https://rcompanion.org/rcompanion/\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup as BS\n",
    "\n",
    "def extract_name_of_the_html(url, add_html_extension):\n",
    "    '''\n",
    "    make a file name based on the URL \"https://rcompanion.org/rcompanion/index.html\".\n",
    "    if `add_html_extension` is True than add `.html` extension\n",
    "    to the file name.\n",
    "    \n",
    "    Return filename\n",
    "    '''\n",
    "    split_url = url.split(\"/\")\n",
    "    fn = split_url[-1]\n",
    "    if add_html_extension:\n",
    "        fn += \".html\"\n",
    "    if fn == 'index.html':\n",
    "        fn = \"rcomp_index.html\"\n",
    "    return fn\n",
    "\n",
    "def get_html_and_save(url):\n",
    "    '''\n",
    "    Take a url for a web page get the html and stores the text.\n",
    "    Returns the html code too\n",
    "    \n",
    "    based on https://stackoverflow.com/a/30890016/8508004\n",
    "    '''\n",
    "    global the_html # so can save using `%store` the variable needs to be global\n",
    "    global fn_save_name # so can save using `%store` the variable needs to be global\n",
    "    hh = urllib.request.urlopen(url)\n",
    "    hbytes = hh.read()\n",
    "\n",
    "    the_html = hbytes.decode(\"utf8\")\n",
    "    #print (the_html[:200])\n",
    "    hh.close()\n",
    "    \n",
    "    fn_save_name = extract_name_of_the_html(url, add_html_extension=False)\n",
    "    \n",
    "    %store the_html > {fn_save_name}\n",
    "    \n",
    "    return the_html \n",
    "\n",
    "\n",
    "pages_and_titles_dict = {}\n",
    "index_html = get_html_and_save(r_companion_index_url)\n",
    "# mine from the Contents panel on the left, the list of the pages\n",
    "nav_code = index_html.split(\"<!-- Begin Navigation -->\")[1].split(\"<!-- End Navigation -->\")[0]\n",
    "contents_code = nav_code.split(\"<ul>Introduction\")[1].split('<div id=\"adskyscraper\">')[0]\n",
    "#print(nav_code )\n",
    "\n",
    "# ul and li tags based on https://stackoverflow.com/a/17246983/8508004\n",
    "soup = BS(nav_code)\n",
    "for ultag in soup.find_all('ul'):\n",
    "    for litag in ultag.find_all('li'):\n",
    "        #print(litag.text.strip())  #<--ends up being same as `print(link.text.strip())`\n",
    "        pass\n",
    "        for link in litag.find_all('a'):\n",
    "            #print(link.get('title')) #based on https://stackoverflow.com/a/32542575/8508004\n",
    "            #print(link.text.strip())\n",
    "            #print(link.get('href')) #based on https://python.gotrained.com/beautifulsoup-extracting-urls/\n",
    "            if link.get('href').startswith(\"http://rcompanion.org/\"):\n",
    "                full_link = link.get('href')\n",
    "            else:\n",
    "                full_link = f\"{site_prefix}{link.get('href')}\"\n",
    "            pages_and_titles_dict[full_link] = link.text.strip()\n",
    "pages_and_titles_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the last one that simply leads to another set of pages and no R code. Plus don't get index from there again since already dealt with what is needed. (Note above, renamed the `index` file from RComp so that it doesn't clobber the Jupyter environment notebook with the same name.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_specifically = [r_companion_index_url, \"http://rcompanion.org/handbook/\"]\n",
    "for p in remove_specifically:\n",
    "    del pages_and_titles_dict[p]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now get the html for each, set up to deal with werid characters, prepate the code blocks and results, and make preliminary markdown from each page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_to_get = list(pages_and_titles_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import urllib.request\n",
    "\n",
    "def move_code_and_results_tags_off_same_line(the_html):\n",
    "    '''\n",
    "    The HTML includes occurences like this:\n",
    "    ```html\n",
    "    <p class=c1>library(DescTools)<br><br>BreslowDayTest(Tabla)</p><p class=c2><br><br>Breslow-Day Test \n",
    "    for Homogeneity of the Odds Ratios<br><br>X-squared = 4.4517, df = 4, p-value = \n",
    "    0.3483<br></p>\n",
    "    ```\n",
    "    \n",
    "    It would be easier to prepar code fences if such occurence were broken up into two lines.\n",
    "    '''\n",
    "    code_start_tag = \"<p class=c1>\"\n",
    "    results_start_tag = \"<p class=c2>\"\n",
    "    new_html = \"\"\n",
    "    for line in the_html.split(\"\\n\"):\n",
    "        if code_start_tag in line and results_start_tag in line:\n",
    "            parts = line.split(results_start_tag)\n",
    "            new_html += parts[0] + \"\\n\" + results_start_tag + parts[1] + \"\\n\"\n",
    "        else:\n",
    "            new_html += line + \"\\n\"\n",
    "    return new_html\n",
    "\n",
    "def prepare_for_fencing_code(the_html):\n",
    "    '''\n",
    "    Takes HTML as a string from an R comp page & based on the c1 and c2 classes(and others) \n",
    "    start and end placing placeholder text to later mark starts and ends of code\n",
    "    blocks. This way can fence the code in the markdown and \n",
    "    have it rendered in code blocks when notebooks made via notedown. \n",
    "    Have to mark the location of clode blocks at the HTMl stage because loses \n",
    "    the class tags when pandoc converts to markdown. So need something that will\n",
    "    survive change to markdown and specify start and end of blocks. Doesn't have\n",
    "    to be the final signals since I can add the backticks and code signal later.\n",
    "    \n",
    "    BASIS FOR RULES:\n",
    "    DEfinitely start with instances of following when code_block not open:\n",
    "    <p class=c1><span style='color:#006600'>###\n",
    "\n",
    "    <p class=c1>hist(Data$ Angle,    <br>\n",
    "\n",
    "\n",
    "    end code block when hit;\n",
    "    <p class=c2>\n",
    "\n",
    "    <p class=j1>\n",
    "    \n",
    "    <p class=j2>\n",
    "    \n",
    "    <h3>\n",
    "    \n",
    "    <h4>\n",
    "    \n",
    "    <h5>\n",
    "    \n",
    "    <p class=MsoNormal>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    Exclude lines that are solely:\n",
    "\n",
    "    <p class=c1>&nbsp;</p>\n",
    "\n",
    "    <p class=c1 style='margin-left:0in'>&nbsp;</p>\n",
    "\n",
    "    <p class=c1 align=center style='text-align:center'>#     #     #</p>\n",
    "\n",
    "    <p class=c1 align=center style='text-align:center'>&nbsp;</p>\n",
    "    \n",
    "    \n",
    "    Also, fix so lines where dashes occur, have spaces in lines like \n",
    "    `### -----------------------------------------------` not changed to line endings, \n",
    "    but I moved this to `prepare_for_coloring_results()` function because\n",
    "    need each line.\n",
    "\n",
    "    '''\n",
    "    # first address any occurences of code and results blocks on same lines, so things easier\n",
    "    the_html = move_code_and_results_tags_off_same_line(the_html)\n",
    "    \n",
    "    # the approach on next two lines was made moot by more general handing of spaces.\n",
    "    #the_html = the_html.replace('### -----------------------------------------------',\n",
    "    #                            '###-----------------------------------------------')\n",
    "    lines_to_ignore = [\"<p class=c1>&nbsp;</p>\",\n",
    "                       \"<p class=c1 style='margin-left:0in'>&nbsp;</p>\",\n",
    "                       \"<p class=c1 align=center style='text-align:center'>#     #     #</p>\",\n",
    "                       \"<p class=c1 align=center style='text-align:center'>&nbsp;</p>\",\n",
    "                       \"<p class=c1 align=center style='text-align:center'>&nbsp;</p>\",\n",
    "                       \"<p class=c1><span style='color:red'>\" #for b_09.html and d_05.html only\n",
    "                      ]\n",
    "    start_placeholder_tag = \"RCOMPxCODExFENCExSTARTSxHERE\"\n",
    "    start_placeholder_tag = \"RCOMPxCODExFENCExSTARTSxHERE\"\n",
    "    end_placeholder_tag = \"RCOMPxCODExFENCExENDSxHERE\"\n",
    "    in_code_block = False\n",
    "    new_html = \"\"\n",
    "    for line in the_html.split(\"\\n\"):\n",
    "        if (not in_code_block and (\n",
    "            line not in lines_to_ignore) and line.strip().startswith(\"<p class=c1>\") ):\n",
    "            in_code_block = True\n",
    "            #split_line = line.split(\"class=c1\",1)\n",
    "            #new_html += split_line[0] + start_placeholder_tag+\"\\n\" + split_line[1]\n",
    "            new_html += start_placeholder_tag+\"\\n\"+line + \"\\n\"\n",
    "        elif (in_code_block and line.strip().startswith(\"<p class=c2>\")) or (\n",
    "            in_code_block and line.strip().startswith(\"<p class=j1>\")) or (\n",
    "            in_code_block and line.strip().startswith(\"<p class=j2>\")) or (\n",
    "            in_code_block and line.strip().startswith(\"<h3>\")) or (\n",
    "            in_code_block and line.strip().startswith(\"<h4>\")) or (\n",
    "            in_code_block and line.strip().startswith(\"<h5>\")) or (\n",
    "            in_code_block and line.strip().startswith(\"<p class=MsoNormal>\")):\n",
    "            new_html += end_placeholder_tag+\"\\n\" + line + \"\\n\"\n",
    "            in_code_block = False\n",
    "        else:\n",
    "            if line.strip() != \"\":\n",
    "                new_html += line + \"\\n\"\n",
    "    \n",
    "    return new_html\n",
    "\n",
    "def avoid_line_breaks_caused_by_comments(the_html):\n",
    "    '''\n",
    "    Comment symbols in clode blocks seem to cause line breaks to be added where there shouldn't be. They should end with `<br>` or `</p>`.\n",
    "    I think if remove the line break and add temporary space handler as an indicator, it should work and\n",
    "    the indicator will be removed in later processing.\n",
    "    '''\n",
    "    start_placeholder_tag = \"RCOMPxCODExFENCExSTARTSxHERE\"\n",
    "    end_placeholder_tag = \"RCOMPxCODExFENCExENDSxHERE\"\n",
    "    space_placeholder = u'ASxSPACE'\n",
    "    split_on_start = the_html.split(start_placeholder_tag)\n",
    "    new_html = \"\"\n",
    "    for p in split_on_start:\n",
    "        if end_placeholder_tag in p:\n",
    "            code_and_not_code_parts = p.split(end_placeholder_tag)\n",
    "            code_part = re.sub('(#.*)\\n(.*)<br>',r'\\1ASxSPACE\\2',code_and_not_code_parts[0],re.S) # This has a drawback in that it can\n",
    "            # insert a space at the start of the next line where the comment doesn't continue on so I added a check for such\n",
    "            # cases below by first no extra, in appropriate space inserted at start of a line\n",
    "            code_part = re.sub('(#.*)\\n(.*)</span></p>',r'\\1ASxSPACE\\2',code_part,re.S) # `</span>` in front of `</p>` is important or it will act on same line again to append on line that follows and ends in `</p>`\n",
    "            code_part = re.sub('(#.*)\\n(.*)</span>!</p>',r'\\1ASxSPACE\\2!',code_part,re.S) # in at least one place (on `b_01.html`) there is a case where exclamation point between `</span>` & `</p>` where comment runs onto next line; this fixes that\n",
    "            code_part = re.sub('<br>ASxSPACE</span>',r'<br>\\nASxSPACE<br>\\n',code_part,re.S)\n",
    "            code_part = re.sub(r'--------\\n</span><br>\\n',r'--------br>\\nASxSPACE<br>\\n',code_part,re.S)\n",
    "            #If inappropriate space entered at start of a line by action of `e.sub('(#.*)\\n(.*)<br>',r'\\1ASxSPACE\\2'`\n",
    "            # remove it, in a simplistic attempt. Example where was happening was in front of  `M2  = 71` in ` d_01`\n",
    "            # first, collect start of original html block and new.==> UPDATE Simplistic approach stopped\n",
    "            # working after I changed something and so it became more complex.\n",
    "            num_letters = 2 #Number of the letters of the first line to use to compare\n",
    "            ''' <--# COMENTING THIS SECTION OUT FOR NOW b/c it makes spaces go away from in front of numbers in second cod block on page d_01. Better way to check there was no real space in front before?\n",
    "            original_line_starts = [l[:len(space_placeholder)+num_letters] for l in code_and_not_code_parts[0].split(\"\\n\")]\n",
    "            new_line_starts = [l[:len(space_placeholder)+num_letters] for l in code_part.split(\"\\n\")]\n",
    "            change_in_line_number = max([len(original_line_starts),len(new_line_starts)])-min([len(original_line_starts),len(new_line_starts)])\n",
    "            #if any of the new ones are same as the old ones with the space_placeholder\n",
    "            # in front, then remove the `space_placeholder`. Can be more than one so\n",
    "            # need to loop on each. Also the index of each shouldn't be able to change\n",
    "            # by more than the difference in number of lines. (This is not perfect\n",
    "            # because problem if start of lines very similar but should cover most simple cases.)\n",
    "            # Originally was enumerating on the original line starts, but then \n",
    "            # it became a problem to determine which new line to edit. So switched\n",
    "            # to enumerating the new line starts and then comparing to subset as if they had been changed\n",
    "            new_line_parts = code_part.split(\"\\n\")\n",
    "            for indx,new_start_pt in enumerate(new_line_starts):\n",
    "                if change_in_line_number:\n",
    "                    if change_in_line_number > 3 and indx < (len(new_line_starts)/2):\n",
    "                        change_in_line_number = 3 # don't make lines to consider above and below expected index too many\n",
    "                    start_pt = indx-change_in_line_number\n",
    "                    if start_pt < 0:\n",
    "                        start_pt = 0\n",
    "                    lines_starts_to_consider = original_line_starts[start_pt:indx+change_in_line_number]\n",
    "                else:\n",
    "                    lines_starts_to_consider = [original_line_starts[indx]]\n",
    "                #lines_starts_to_consider=[space_placeholder+x[:(len(x)-len(space_placeholder))] for x in lines_starts_to_consider]\n",
    "                lines_starts_to_consider=[x[:num_letters]for x in lines_starts_to_consider] # just want first two letters because that is all\n",
    "                # that can match when remove space holder\n",
    "                if new_start_pt[:num_letters] in lines_starts_to_consider and (\n",
    "                    new_start_pt[:len(space_placeholder)] == space_placeholder):\n",
    "                    new_line_parts[indx] = new_line_parts[indx][len(space_placeholder):] # remove step\n",
    "            code_part = \"\\n\".join(new_line_parts)\n",
    "            '''\n",
    "            # do that with splitting on `<br>` too because example where was happening was in front of  `M2  = 71` in ` d_01\n",
    "            # actually occurs after `<br>`\n",
    "            original_line_starts = [l[:len(space_placeholder)+num_letters + 1] for l in code_and_not_code_parts[0].split(\"<br>\")] #+ 1 to account for linebreak\n",
    "            new_line_starts = [l[:len(space_placeholder)+num_letters] for l in code_part.split(\"<br>\")]\n",
    "            change_in_line_number = max([len(original_line_starts),len(new_line_starts)])-min([len(original_line_starts),len(new_line_starts)])\n",
    "            new_line_parts = code_part.split(\"<br>\")\n",
    "            for indx,new_start_pt in enumerate(new_line_starts):\n",
    "                if change_in_line_number:\n",
    "                    if change_in_line_number > 3 and indx < (len(new_line_starts)/2):\n",
    "                        change_in_line_number = 3 # don't make lines to consider above and below expected index too many\n",
    "                    start_pt = indx-change_in_line_number\n",
    "                    if start_pt < 0:\n",
    "                        start_pt = 0\n",
    "                    lines_starts_to_consider = original_line_starts[start_pt:indx+change_in_line_number+1]\n",
    "                else:\n",
    "                    lines_starts_to_consider = [original_line_starts[indx]]\n",
    "                #lines_starts_to_consider=[space_placeholder+x[:(len(x)-len(space_placeholder))] for x in lines_starts_to_consider]\n",
    "                # remove first character because after <br>, it normally is a line break\n",
    "                lines_starts_to_consider=[x[1:]for x in lines_starts_to_consider]\n",
    "                lines_starts_to_consider=[x[:num_letters]for x in lines_starts_to_consider] # just want first two letters because that is all\n",
    "                # that can match when remove space holder\n",
    "                # So if it is a space holder at start and same letters as original start\n",
    "                #if \"M2\" in lines_starts_to_consider:\n",
    "                #   print(new_start_pt[:len(space_placeholder)] == space_placeholder)\n",
    "                if new_start_pt[len(\n",
    "                    space_placeholder):len(space_placeholder)+num_letters] in lines_starts_to_consider and (\n",
    "                    new_start_pt[:len(space_placeholder)] == space_placeholder):\n",
    "                    new_line_parts[indx] = new_line_parts[indx][len(space_placeholder):] # remove step\n",
    "            code_part = \"<br>\".join(new_line_parts)\n",
    "            new_html += (start_placeholder_tag  + \"\\n\" +\n",
    "                                    code_part + \"\\n\" + end_placeholder_tag  + \"\\n\" + \n",
    "                                    code_and_not_code_parts[1] )\n",
    "        else:\n",
    "            new_html += p\n",
    "    \n",
    "    return new_html\n",
    "\n",
    "\n",
    "def prepare_for_coloring_results(the_html):\n",
    "    '''\n",
    "    Takes HTML as a string from an R comp page & based on c2 class tag, adds\n",
    "    placeholder that can be used for coloring results later so they appear\n",
    "    like they do in HTML.\n",
    "    \n",
    "    It won't be perfect because is simplistic for now % won't handle \n",
    "    examples like below where spans two lines, but better than nothing and most seem\n",
    "    to match the simplistic model:\n",
    "    <p class=c2><img width=480 height=255\n",
    "    src=\"images/c_01_03.jpg\"></p>\n",
    "    '''\n",
    "    lines_to_ignore = [\"<p class=c2>&nbsp;</p>\"]\n",
    "    results_class_tag = '<p class=c2>'\n",
    "    results_class__end_tag = '</p>'\n",
    "    start_placeholder_tag = \"RCOMPxRESULTxLINExSTART\"\n",
    "    end_placeholder_tag = \"RCOMPxRESULTxLINExEND\"\n",
    "    bracket_start_plchlder = \"BRACKETxSTARTxPLCHLDR\"#replace real brackets early so can be sure source later\n",
    "    bracket_end_plchlder = \"BRACKETxENDxPLCHLDR\"#replace real brackets early so can be sure source later\n",
    "    space_placeholder = \"ASxSPACE\" # Want to substitute now so not causing a new line when PANDOC converts to markdown\n",
    "    new_html = \"\"\n",
    "    continues2next_line = False\n",
    "    for line in the_html.split(\"\\n\"):\n",
    "        #while have lines address those with hashes to have the spaces protected.\n",
    "        if \"#\" in line:\n",
    "            line.replace(\" \",space_placeholder)\n",
    "        if continues2next_line and (line not in lines_to_ignore):\n",
    "            if line.strip().endswith(results_class__end_tag):\n",
    "                new_html += line[:-(len(results_class__end_tag))].strip().replace(\" \",space_placeholder) + end_placeholder_tag + \"\\n\"\n",
    "                continues2next_line = False\n",
    "            else:\n",
    "                new_html += line.strip().replace(\" \",space_placeholder) + space_placeholder\n",
    "        elif (line not in lines_to_ignore) and (\n",
    "            line.strip().startswith(results_class_tag)) and (\n",
    "            line.strip().endswith(results_class__end_tag)):\n",
    "            line = line.replace(\"[\",bracket_start_plchlder) #replace real brackets early so can be sure source later\n",
    "            line = line.replace(\"]\",bracket_end_plchlder) #replace real brackets early so can be sure source later\n",
    "            new_html += start_placeholder_tag + line[len(\n",
    "                results_class_tag):-(len(results_class__end_tag))].strip(\n",
    "                ).replace(\" \",space_placeholder) + end_placeholder_tag + \"\\n\"\n",
    "        elif (line not in lines_to_ignore) and (\n",
    "            line.strip().startswith(results_class_tag)):\n",
    "            line = line.replace(\"[\",bracket_start_plchlder) #replace real brackets early so can be sure source later\n",
    "            line = line.replace(\"]\",bracket_end_plchlder) #replace real brackets early so can be sure source later\n",
    "            new_html += start_placeholder_tag + line[len(\n",
    "                results_class_tag):].strip(\n",
    "                ).replace(\" \",space_placeholder) + space_placeholder\n",
    "            continues2next_line = True\n",
    "        elif (line not in lines_to_ignore):\n",
    "            new_html += line + \"\\n\"\n",
    "    return new_html\n",
    "\n",
    "def extract_name_of_the_html(url, add_html_extension):\n",
    "    '''\n",
    "    make a file name based on the URL \"https://rcompanion.org/rcompanion/index.html\".\n",
    "    if `add_html_extension` is True than add `.html` extension\n",
    "    to the file name.\n",
    "    \n",
    "    Return filename\n",
    "    '''\n",
    "    split_url = url.split(\"/\")\n",
    "    fn = split_url[-1]\n",
    "    if add_html_extension:\n",
    "        fn += \".html\"\n",
    "    return fn\n",
    "\n",
    "def get_html_and_save(url):\n",
    "    '''\n",
    "    Take a url for a web page get the html and store the text.\n",
    "    \n",
    "    return the name of the html and the name of file to save.\n",
    "    (Turns out `%store` magics didn't work in the function?!)\n",
    "    \n",
    "    based on https://stackoverflow.com/a/30890016/8508004\n",
    "    '''\n",
    "    hh = urllib.request.urlopen(url)\n",
    "    hbytes = hh.read()\n",
    "\n",
    "    the_html = hbytes.decode(\"utf8\")\n",
    "    #print (the_html[:200])\n",
    "    hh.close()\n",
    "    fn_save_name = extract_name_of_the_html(url, add_html_extension=False)\n",
    "    \n",
    "    #%store the_html > {fn_save_name} #seems cannot use this in a function?;\n",
    "    # probably because it needs to be a global and here it would be local\n",
    "    # variable it would be trying to save.\n",
    "    \n",
    "    return the_html,fn_save_name\n",
    "import re\n",
    "htmls_collected = []\n",
    "markdowns_made = []\n",
    "for url in urls_to_get:\n",
    "    the_html,fn_save_name = get_html_and_save(url)\n",
    "    if '<h1>Repeated Gâ€“tests of Goodness-of-Fit' in the_html and \"<p class=c1><span style='color:red'>\" not in the_html:\n",
    "        sys.stderr.write(\"It seems the issue on b_09.html with `<p class=c1><span style='color:red'>` has been fixed.\"\n",
    "            \" Please remove the appropriate line from `lines_to_ignore` in `prepare_for_fencing_code()`  if fixed in all.\")\n",
    "    if '<h1>One-way Anova<' in the_html and \"<p class=c1><span style='color:red'>\" not in the_html:\n",
    "        sys.stderr.write(\"It seems the issue on d_05.html with `<p class=c1><span style='color:red'>` has been fixed.\"\n",
    "            \" Please remove the appropriate line from `lines_to_ignore` in `prepare_for_fencing_code()` if fixed in all.\")\n",
    "    the_html = the_html.replace(\"<p class=c1><span style='color:red'>\",\"<p class=c2>\")\n",
    "    space_placeholder = u'ASxSPACE'\n",
    "    the_html = the_html.replace(u'\\xa0', space_placeholder)\n",
    "    the_html = the_html.replace(u'&nbsp;', \"nonXbreakingXspace\")\n",
    "    # First 'normalize' the text. Was hopting change the weird `\\xa0` that I am seeing as 'space' characters\n",
    "    # in the tables INTO ACTUAL SPACES; based on https://stackoverflow.com/a/34669482/8508004 . But \n",
    "    # `the_html = unicodedata.normalize(\"NFKD\", the_html)` was just seeming to remove them.\n",
    "    import unicodedata\n",
    "    the_html = unicodedata.normalize(\"NFKD\", the_html) #`NFKD` removed the the weird `\\xa0` characters but didn't replace with space; however, `the_html = the_html.replace(u'\\xa0', the_html)` kept getting killed; `NFC` & `NFD` didn't touch the `\\xa0` chars; NFKC seems to remove them and a lot of other actual content??!?\n",
    "    the_html = prepare_for_fencing_code(the_html)\n",
    "    the_html = avoid_line_breaks_caused_by_comments(the_html)\n",
    "    the_html = prepare_for_coloring_results(the_html)\n",
    "    space_placeholder_t = u'TEMPxHLD'\n",
    "    the_html = the_html.replace(u' ', space_placeholder_t) #temporarily mask spaces so pandoc doesn't add line breaks between spaces and numbers\n",
    "    %store the_html > {fn_save_name}\n",
    "    htmls_collected.append(fn_save_name)\n",
    "    markdown_name = fn_save_name.rsplit(\".html\")[0] + \".md\"\n",
    "    !pandoc -s -f html -t markdown {fn_save_name} -o {markdown_name}\n",
    "    #remove the temporarily masked spaces\n",
    "    with open(markdown_name, 'r') as input:\n",
    "        the_md=input.read()\n",
    "    the_md = the_md.replace(space_placeholder_t,u' ')\n",
    "    the_md = the_md.replace(\"nonXbreakingXspace\",u' ')\n",
    "    %store the_md > {markdown_name}\n",
    "    sys.stderr.write(\"'{}' has been generated.\\n\".format(markdown_name))\n",
    "    markdowns_made.append(markdown_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unescape the escaping of symbols and punctuation in what are to be code blocks\n",
    "def unescape_punc_symbols(s, md_name):\n",
    "    '''\n",
    "    Takes a string and replaces the characters as described below:\n",
    "    \\\" goes to \"\n",
    "    \\# goes to #\n",
    "    \\$ goes to $\n",
    "    \\~ goes to ~\n",
    "    \\> goes to >\n",
    "    \\< goes to <\n",
    "    \\' goes to '\n",
    "    \\_ goes to _\n",
    "    \\- goes to -\n",
    "    \\* goes to *\n",
    "    \\| goes to |\n",
    "    \\^ goes to ^\n",
    "    \\[ goes to [\n",
    "    \\] goes to ]\n",
    "    `[TEXT]{style=\"color:#006600\"}` goes to `TEXT`\n",
    "    `pp. NUMBER--` goes to `pp. NUMBER -` \n",
    "    \\END_OF_LINE goes to just END_OF_LINE\n",
    "    -- in lines with less than 10 dashes go to single dashes\n",
    "    \n",
    "    Also requires the name of the mardown so any special handling can be carried out\n",
    "    '''\n",
    "    s = s.replace(r'\\\"','\"') # oddly why the lower two worked without being raw, this wouldn't. Saved by https://stackoverflow.com/a/6718322/8508004\n",
    "    s = s.replace(r'\\#','#')\n",
    "    s = s.replace(r'\\$','$')\n",
    "    s = s.replace(r'\\~','~')\n",
    "    s = s.replace(r'\\>','>')\n",
    "    s = s.replace(r'\\<','<')\n",
    "    s = s.replace(r\"\\'\",\"'\")\n",
    "    s = s.replace(r'\\_','_')\n",
    "    s = s.replace(r'\\-','-')\n",
    "    s = s.replace(r'\\*','*')\n",
    "    s = s.replace(r'\\|','|')\n",
    "    s = s.replace(r'\\^','^')\n",
    "    s = s.replace(r'\\[','[')\n",
    "    s = s.replace(r'\\]',']')\n",
    "    #s = ' '.join(re.findall(r'\\[(.*?)\\]{style=\\\"color:#006600\\\"}', s,re.S))\n",
    "    # Use bruteforce because too hard to combine all needed it seems; however, skip \n",
    "    # for b_09 where text `title: 'R Companion: Repeated G--tests of Goodness-of-Fit'` is found\n",
    "    # because otherwise causes too much stuff deleted since that code features a lot of brackets\n",
    "    if \"b_09.md\" != md_name:\n",
    "        without_brackets = \"\"\n",
    "        tag = ']{style=\"color:#006600\"}'\n",
    "        total_occurences = s.count(tag)\n",
    "        for indx,p in enumerate(s.split(tag)):\n",
    "            if indx < total_occurences:\n",
    "                p += tag\n",
    "            #print(\"p\",p)\n",
    "            if tag in p:\n",
    "                o= re.findall(r'(.*?)\\[(.*?)\\]{style=\\\"color:#006600\\\"}(.*?)', p, re.S) # because multiple groups means a list of tuples, see https://howchoo.com/g/zdvmogrlngz/python-regexes-findall-search-and-match\n",
    "                flattened = [item for sublist in o for item in sublist]\n",
    "                without_brackets += \" \".join(flattened)\n",
    "            else:\n",
    "                without_brackets += p\n",
    "        s = without_brackets\n",
    "    else:\n",
    "        s = s.replace(r'[#',r'#')\n",
    "    s = re.sub(', pp.\\n',', pp. ',s) # as prep for fixing `--` for page numbering, remove extra end of line pandoc puts after `pp.`\n",
    "    s = re.sub('(pp. \\d+.).',r'\\1',s) # note the use of `r` for capture grpup from https://lzone.de/examples/Python%20re.sub\n",
    "    #Now to handle removing the backslashes at end of line (WAY HARDER THAN EXPECTED TO DO THIS)\n",
    "    #s = s.replace('\\\\','') # This, based on https://stackoverflow.com/a/17327500/8508004, seems to work to remove backslashes at ends of line but isn't specifying end of line. Prefer to use regex to specify\n",
    "    #s = re.sub('\\\\$','',s) # doesn't seem to do what above line does at all. I'd hoped it would and then restrict to `\\` at end of lines with regex.\n",
    "    # So bruteforce recognizing end of a line with below by going line by line\n",
    "    new_s = \"\"\n",
    "    #print(s)\n",
    "    for l in s.split(\"\\n\"):\n",
    "        if l.endswith(\"\\\\\"):\n",
    "            new_s += l[:-1]+\"\\n\"\n",
    "        else:\n",
    "            new_s += l+\"\\n\"\n",
    "            \n",
    "    return new_s\n",
    "\n",
    "def unescape_code_portions(md_text):\n",
    "    '''\n",
    "    Takes markdown file name and opens the markdown and fixes the\n",
    "    punctuation and symbols so they aren't backslashed escaped.\n",
    "    \n",
    "    BASIS FOR RULES:\n",
    "    \\\" goes to \"\n",
    "    \\# goes to #\n",
    "    \\$ goes to $\n",
    "    \\~ goes to ~\n",
    "    \\> goes to >\n",
    "    \\< goes to <\n",
    "    \\' goes to '\n",
    "    \\_ goes to _\n",
    "    \\- goes to -\n",
    "    \\* goes to *\n",
    "    \\| goes to |\n",
    "    \\^ goes to ^\n",
    "    \\[ goes to [\n",
    "    \\] goes to ]\n",
    "    `[TEXT]{style=\"color:#006600\"}` goes to `TEXT`\n",
    "    `pp. NUMBER--` goes to `pp. NUMBER -` \n",
    "    \\END_OF_LINE goes to just END_OF_LINE\n",
    "\n",
    "    '''\n",
    "    lines_to_ignore = [\"\",]\n",
    "    start_placeholder_tag = \"RCOMPxCODExFENCExSTARTSxHERE\"\n",
    "    end_placeholder_tag = \"RCOMPxCODExFENCExENDSxHERE\"\n",
    "    in_code_block = False\n",
    "    new_md_text = \"\"\n",
    "    with open(md, 'r') as input:\n",
    "        all_md=input.read()\n",
    "    blocks= all_md.split(start_placeholder_tag)\n",
    "    for b in blocks:\n",
    "        if end_placeholder_tag in b:\n",
    "            parts_of_block = b.split(end_placeholder_tag)\n",
    "            #new_md_text += start_placeholder_tag + parts_of_block[0].encode('utf-8').decode('unicode_escape') + end_placeholder_tag + \" \".join(parts_of_block[1:]) # based on comments in https://stackoverflow.com/a/1885197/8508004  <-- didn't work\n",
    "            #new_md_text += start_placeholder_tag + decode(encode(parts_of_block[0], 'latin-1', 'backslashreplace'), 'unicode-escape')+ end_placeholder_tag + \" \".join(parts_of_block[1:]) # based on https://stackoverflow.com/a/57192592/8508004 <-- works all, INCLUDING CASES OF '\\\"' whereas `s = s.replace('\\\"','\"')` didn't, but encode.decode removes the line breaks too\n",
    "            new_md_text += start_placeholder_tag + unescape_punc_symbols(parts_of_block[0],md) + end_placeholder_tag + \" \".join(parts_of_block[1:]) # for the quote handling, I needed https://stackoverflow.com/a/6718322/8508004. See the `unescape_punc_symbols` function.\n",
    "        else:\n",
    "            new_md_text += b\n",
    "    return new_md_text\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "\n",
    "for md in markdowns_made:\n",
    "    new_md = unescape_code_portions(md)\n",
    "    %store new_md > temp.txt \n",
    "    !mv temp.txt {md}\n",
    "    sys.stderr.write(f\"Code blocks unescaped in {md}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collecting all the results\n",
    "-----------------------------------\n",
    "\n",
    "Run the next cell to gather and archive both the produced markdown files.  \n",
    "Also collect the two lists used here as json files so the contents can be used for automating filling in the markdown into Jupyter inpynb files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_file_name = \"FirstSetmarkdown_from_RCompanion.tar.gz\"\n",
    "import os\n",
    "import sys\n",
    "# store `urls_to_get` and `markdowns_made` as json since lighter-weight and more portable than pickling\n",
    "# and the order of them wll correspond to the index I made so I can use them with papermill \n",
    "# in conjuction without needing to make a new dictionary.\n",
    "RCompanion_urls_to_get_storedfn = \"RCompanion_urls_to_get.json\"\n",
    "RCompanion_markdowns_made_storedfn = \"RCompanion_markdowns_made.json\"\n",
    "import json\n",
    "with open(RCompanion_urls_to_get_storedfn, 'w') as f:\n",
    "    json.dump(urls_to_get, f)\n",
    "with open(RCompanion_markdowns_made_storedfn, 'w') as f:\n",
    "    json.dump(markdowns_made, f)\n",
    "files_to_archive = markdowns_made + [RCompanion_urls_to_get_storedfn] + [RCompanion_markdowns_made_storedfn]\n",
    "!tar czf {archive_file_name} {\" \".join(files_to_archive)}\n",
    "sys.stderr.write(\"***************************DONE***********************************\\n\"\n",
    "    \"'{}' generated. Download it.\\n\"\n",
    "    \"***************************DONE***********************************\".format(archive_file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\" \".join(markdowns_made)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow-up this with `Generating R Companion notebooks from extracted markdown via notedown.ipynb`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
