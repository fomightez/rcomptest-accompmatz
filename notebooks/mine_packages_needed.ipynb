{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting R Comp html and making install.R file\n",
    "\n",
    "Meant to be run in sessions launched from [here](https://github.com/fomightez/rcomp_testenv). (This can also be run [here](https://github.com/fomightez/muscle-binder) where I added the recent version of pandoc on Feb 3, 2019. That version added conversion to markdown.) \n",
    "\n",
    "This is to make a binder-launchable environment with all the necessary R packages installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_companion_index_url = \"https://rcompanion.org/rcompanion/index.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_prefix = \"https://rcompanion.org/rcompanion/\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup as BS\n",
    "\n",
    "def extract_name_of_the_html(url, add_html_extension):\n",
    "    '''\n",
    "    make a file name based on the URL \"https://rcompanion.org/rcompanion/index.html\".\n",
    "    if `add_html_extension` is True than add `.html` extension\n",
    "    to the file name.\n",
    "    \n",
    "    Return filename\n",
    "    '''\n",
    "    split_url = url.split(\"/\")\n",
    "    fn = split_url[-1]\n",
    "    if add_html_extension:\n",
    "        fn += \".html\"\n",
    "    return fn\n",
    "\n",
    "def get_html_and_save(url):\n",
    "    '''\n",
    "    Take a url for a web page get the html and stores the text.\n",
    "    Returns the html code too\n",
    "    \n",
    "    based on https://stackoverflow.com/a/30890016/8508004\n",
    "    '''\n",
    "    global the_html # so can save using `%store` the variable needs to be global\n",
    "    global fn_save_name # so can save using `%store` the variable needs to be global\n",
    "    hh = urllib.request.urlopen(url)\n",
    "    hbytes = hh.read()\n",
    "\n",
    "    the_html = hbytes.decode(\"utf8\")\n",
    "    #print (the_html[:200])\n",
    "    hh.close()\n",
    "    \n",
    "    fn_save_name = extract_name_of_the_html(url, add_html_extension=False)\n",
    "    \n",
    "    %store the_html > {fn_save_name}\n",
    "    \n",
    "    return the_html \n",
    "\n",
    "\n",
    "pages_and_titles_dict = {}\n",
    "index_html = get_html_and_save(r_companion_index_url)\n",
    "# mine from the Contents panel on the left, the list of the pages\n",
    "nav_code = index_html.split(\"<!-- Begin Navigation -->\")[1].split(\"<!-- End Navigation -->\")[0]\n",
    "contents_code = nav_code.split(\"<ul>Introduction\")[1].split('<div id=\"adskyscraper\">')[0]\n",
    "#print(nav_code )\n",
    "\n",
    "# ul and li tags based on https://stackoverflow.com/a/17246983/8508004\n",
    "soup = BS(nav_code)\n",
    "for ultag in soup.find_all('ul'):\n",
    "    for litag in ultag.find_all('li'):\n",
    "        #print(litag.text.strip())  #<--ends up being same as `print(link.text.strip())`\n",
    "        pass\n",
    "        for link in litag.find_all('a'):\n",
    "            #print(link.get('title')) #based on https://stackoverflow.com/a/32542575/8508004\n",
    "            #print(link.text.strip())\n",
    "            #print(link.get('href')) #based on https://python.gotrained.com/beautifulsoup-extracting-urls/\n",
    "            if link.get('href').startswith(\"http://rcompanion.org/\"):\n",
    "                full_link = link.get('href')\n",
    "            else:\n",
    "                full_link = f\"{site_prefix}{link.get('href')}\"\n",
    "            pages_and_titles_dict[full_link] = link.text.strip()\n",
    "pages_and_titles_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, do not remove a few that I already converted to notebooks because I need to get packages those need, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''drafts_made_already = [\n",
    "    \"Reading_SAS_Datalines_in_R.ipynb\",\n",
    "    \"Power_Analysis.ipynb\",\n",
    "    \"Exact_Test_of_Goodness-of-Fit.ipynb\"\n",
    "    \n",
    "]\n",
    "\n",
    "drafts_made_already_for_matching = [x.rsplit(\".ipynb\")[0].replace(\"_\",\" \") for x in drafts_made_already]\n",
    "ones_to_remove = [] # need to make a list because cannot delete while iterating over\n",
    "for url,page_name in pages_and_titles_dict.items():\n",
    "    if page_name in drafts_made_already_for_matching:\n",
    "        ones_to_remove.append(url)\n",
    "for t in ones_to_remove:\n",
    "    del pages_and_titles_dict[t]\n",
    "pages_and_titles_dict\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the last one as it doesn't include code. (Just leads to another online book by the author Salvatore.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_specifically = \"http://rcompanion.org/handbook/\"\n",
    "del pages_and_titles_dict[remove_specifically]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now get the html for each and make markdown from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_to_get = list(pages_and_titles_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import urllib.request\n",
    "\n",
    "\n",
    "def extract_name_of_the_html(url, add_html_extension):\n",
    "    '''\n",
    "    make a file name based on the URL \"https://rcompanion.org/rcompanion/index.html\".\n",
    "    if `add_html_extension` is True than add `.html` extension\n",
    "    to the file name.\n",
    "    \n",
    "    Return filename\n",
    "    '''\n",
    "    split_url = url.split(\"/\")\n",
    "    fn = split_url[-1]\n",
    "    if add_html_extension:\n",
    "        fn += \".html\"\n",
    "    return fn\n",
    "\n",
    "def get_html_and_save(url):\n",
    "    '''\n",
    "    Take a url for a web page get the html and store the text.\n",
    "    \n",
    "    return the name of the html and the name of file to save.\n",
    "    (Turns out `%store` magics didn't work in the function?!)\n",
    "    \n",
    "    based on https://stackoverflow.com/a/30890016/8508004\n",
    "    '''\n",
    "    hh = urllib.request.urlopen(url)\n",
    "    hbytes = hh.read()\n",
    "\n",
    "    the_html = hbytes.decode(\"utf8\")\n",
    "    #print (the_html[:200])\n",
    "    hh.close()\n",
    "    fn_save_name = extract_name_of_the_html(url, add_html_extension=False)\n",
    "    \n",
    "    #%store the_html > {fn_save_name} #seems cannot use this in a function?;\n",
    "    # probably because it needs to be a global and here it would be local\n",
    "    # variable it would be trying to save.\n",
    "    \n",
    "    return the_html,fn_save_name\n",
    "\n",
    "htmls_collected = []\n",
    "markdowns_made = []\n",
    "for url in urls_to_get:\n",
    "    the_html,fn_save_name = get_html_and_save(url)\n",
    "    %store the_html > {fn_save_name}\n",
    "    htmls_collected.append(fn_save_name)\n",
    "    markdown_name = fn_save_name.rsplit(\".html\")[0] + \".md\"\n",
    "    !pandoc -s -f html -t markdown {fn_save_name} -o {markdown_name}\n",
    "    sys.stderr.write(\"'{}' has been generated.\\n\".format(markdown_name))\n",
    "    markdowns_made.append(markdown_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterating over markdown produced and collect packages needed for running all R code\n",
    "--------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#markdowns_made = [\"d_06.md\"] # Uncomment for debugging only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_libraries_from_md(md):\n",
    "    '''\n",
    "    Go through markdown line by line and collect packages needed from lines like:\n",
    "    \n",
    "    if(!require(DescTools)){install.packages(\\\"DescTools\\\")}\\\n",
    "    if(!require(RVAideMemoire)){install.packages(\\\"RVAideMemoire\\\")}\\\n",
    "    \n",
    "    Return packages as list\n",
    "    '''\n",
    "    packages_needed = []\n",
    "    with open(md, 'r') as input:\n",
    "        for line in input:\n",
    "            if (line.strip().startswith(\"if(!require\")) and (\n",
    "                \"{install.packages(\" in line):\n",
    "                package_nom = line.split('{install.packages(')[1].split('\\\")}')[0].strip()\n",
    "                packages_needed.append(package_nom[2:-1])\n",
    "    return packages_needed\n",
    "\n",
    "R_packages = []\n",
    "for md in markdowns_made:\n",
    "    extracted_packages = extract_libraries_from_md(md)\n",
    "    R_packages += extracted_packages\n",
    "R_packages = list(set(R_packages))\n",
    "R_packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make the install.R file for the repository\n",
    "\n",
    "While doing this, address any peculiarites I have seen come up. For example, for `RVAideMemoire`, I've seen that simply including `install.packages(\"RVAideMemoire\")` won't result in an environment that allows it to run when launched via Binder. It reports that it needs `mixOmics` to work as well and it doesn't seem to get installed as `mixOmics` has been moved from CRAN / MRAN to Bioconductor. I found that it was then necessary to add in the special handling needed to get that in the `Install.R` file if `RVAideMemoire` is among the list of libraries required.\n",
    "\n",
    "install.packages(\"BiocManager\")\n",
    "BiocManager::install(\"mixOmics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_additions_needed_for_RVAideMemoire = '''\\\n",
    "install.packages(\"BiocManager\")\n",
    "BiocManager::install(\"mixOmics\")\n",
    "'''\n",
    "\n",
    "basic_line = 'install.packages(\"PLACEHOLDER\")'\n",
    "text_2_save = ''\n",
    "if \"RVAideMemoire\" in R_packages:\n",
    "        text_2_save += special_additions_needed_for_RVAideMemoire\n",
    "for x in R_packages:\n",
    "    text_2_save += basic_line.replace(\"PLACEHOLDER\",x)\n",
    "    text_2_save += \"\\n\"\n",
    "%store text_2_save > install.R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download `install.R` for placing in the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "archive_file_name = \"FirstSetmarkdown_from_RCompanion.tar.gz\"\n",
    "import os\n",
    "import sys\n",
    "# store `urls_to_get` and `markdowns_made` as json since lighter-weight and more portable than pickling\n",
    "# and the order of them wll correspond to the index I made so I can use them with papermill \n",
    "# in conjuction without needing to make a new dictionary.\n",
    "RCompanion_urls_to_get_storedfn = \"RCompanion_urls_to_get.json\"\n",
    "RCompanion_markdowns_made_storedfn = \"RCompanion_markdowns_made.json\"\n",
    "import json\n",
    "with open(RCompanion_urls_to_get_storedfn, 'w') as f:\n",
    "    json.dump(urls_to_get, f)\n",
    "with open(RCompanion_markdowns_made_storedfn, 'w') as f:\n",
    "    json.dump(markdowns_made, f)\n",
    "files_to_archive = markdowns_made + [RCompanion_urls_to_get_storedfn] + [RCompanion_markdowns_made_storedfn]\n",
    "!tar czf {archive_file_name} {\" \".join(files_to_archive)}\n",
    "sys.stderr.write(\"***************************DONE***********************************\\n\"\n",
    "    \"'{}' generated. Download it.\\n\"\n",
    "    \"***************************DONE***********************************\".format(archive_file_name))\n",
    "''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow-up this with `?????`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def executeSomething():\n",
    "    #code here\n",
    "    print ('.')\n",
    "    time.sleep(480) #60 seconds times 8 minutes\n",
    "\n",
    "while True:\n",
    "    executeSomething()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
