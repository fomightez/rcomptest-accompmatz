{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting R Comp html and making install.R file\n",
    "\n",
    "Meant to be run in sessions launched from [here](https://github.com/fomightez/rcomp_testenv). However, because it doesn't need anything special except the one package that gets installed as the notebook runs, it can be run in pretty much any session launched via MyBinder.org or in a current JupyterHub environment.\n",
    "\n",
    "This is to make a Binder-launchable environment with all the necessary R packages installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_companion_index_url = \"https://rcompanion.org/rcompanion/index.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_prefix = \"https://rcompanion.org/rcompanion/\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup as BS\n",
    "\n",
    "def extract_name_of_the_html(url, add_html_extension):\n",
    "    '''\n",
    "    make a file name based on the URL \"https://rcompanion.org/rcompanion/index.html\".\n",
    "    if `add_html_extension` is True than add `.html` extension\n",
    "    to the file name.\n",
    "    \n",
    "    Return filename\n",
    "    '''\n",
    "    split_url = url.split(\"/\")\n",
    "    fn = split_url[-1]\n",
    "    if add_html_extension:\n",
    "        fn += \".html\"\n",
    "    if fn == 'index.html':\n",
    "        fn = \"rcomp_index.html\"\n",
    "    return fn\n",
    "\n",
    "def get_html_and_save(url):\n",
    "    '''\n",
    "    Take a url for a web page get the html and stores the text.\n",
    "    Returns the html code too\n",
    "    \n",
    "    based on https://stackoverflow.com/a/30890016/8508004\n",
    "    '''\n",
    "    global the_html # so can save using `%store` the variable needs to be global\n",
    "    global fn_save_name # so can save using `%store` the variable needs to be global\n",
    "    hh = urllib.request.urlopen(url)\n",
    "    hbytes = hh.read()\n",
    "\n",
    "    the_html = hbytes.decode(\"utf8\")\n",
    "    #print (the_html[:200])\n",
    "    hh.close()\n",
    "    \n",
    "    fn_save_name = extract_name_of_the_html(url, add_html_extension=False)\n",
    "    \n",
    "    %store the_html > {fn_save_name}\n",
    "    \n",
    "    return the_html \n",
    "\n",
    "\n",
    "pages_and_titles_dict = {}\n",
    "index_html = get_html_and_save(r_companion_index_url)\n",
    "# mine from the Contents panel on the left, the list of the pages\n",
    "nav_code = index_html.split(\"<!-- Begin Navigation -->\")[1].split(\"<!-- End Navigation -->\")[0]\n",
    "contents_code = nav_code.split(\"<ul>Introduction\")[1].split('<div id=\"adskyscraper\">')[0]\n",
    "#print(nav_code )\n",
    "\n",
    "# ul and li tags based on https://stackoverflow.com/a/17246983/8508004\n",
    "soup = BS(nav_code)\n",
    "for ultag in soup.find_all('ul'):\n",
    "    for litag in ultag.find_all('li'):\n",
    "        #print(litag.text.strip())  #<--ends up being same as `print(link.text.strip())`\n",
    "        pass\n",
    "        for link in litag.find_all('a'):\n",
    "            #print(link.get('title')) #based on https://stackoverflow.com/a/32542575/8508004\n",
    "            #print(link.text.strip())\n",
    "            #print(link.get('href')) #based on https://python.gotrained.com/beautifulsoup-extracting-urls/\n",
    "            if link.get('href').startswith(\"http://rcompanion.org/\"):\n",
    "                full_link = link.get('href')\n",
    "            else:\n",
    "                full_link = f\"{site_prefix}{link.get('href')}\"\n",
    "            pages_and_titles_dict[full_link] = link.text.strip()\n",
    "pages_and_titles_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, do not remove a few that I already converted to notebooks because I need to get packages those need, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''drafts_made_already = [\n",
    "    \"Reading_SAS_Datalines_in_R.ipynb\",\n",
    "    \"Power_Analysis.ipynb\",\n",
    "    \"Exact_Test_of_Goodness-of-Fit.ipynb\"\n",
    "    \n",
    "]\n",
    "\n",
    "drafts_made_already_for_matching = [x.rsplit(\".ipynb\")[0].replace(\"_\",\" \") for x in drafts_made_already]\n",
    "ones_to_remove = [] # need to make a list because cannot delete while iterating over\n",
    "for url,page_name in pages_and_titles_dict.items():\n",
    "    if page_name in drafts_made_already_for_matching:\n",
    "        ones_to_remove.append(url)\n",
    "for t in ones_to_remove:\n",
    "    del pages_and_titles_dict[t]\n",
    "pages_and_titles_dict\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the last one as it doesn't include code. (Just leads to another online book by the author Salvatore.) Also remove the index, so I don't clobber the one in the environment. (Note above, renamed the `index` file from RComp so that it doesn't clobber the Jupyter environment notebook with the same name.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_specifically = [r_companion_index_url, \"http://rcompanion.org/handbook/\"]\n",
    "for p in remove_specifically:\n",
    "    del pages_and_titles_dict[p]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now get the html for each and make markdown from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_to_get = list(pages_and_titles_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import urllib.request\n",
    "\n",
    "\n",
    "def extract_name_of_the_html(url, add_html_extension):\n",
    "    '''\n",
    "    make a file name based on the URL \"https://rcompanion.org/rcompanion/index.html\".\n",
    "    if `add_html_extension` is True than add `.html` extension\n",
    "    to the file name.\n",
    "    \n",
    "    Return filename\n",
    "    '''\n",
    "    split_url = url.split(\"/\")\n",
    "    fn = split_url[-1]\n",
    "    if add_html_extension:\n",
    "        fn += \".html\"\n",
    "    return fn\n",
    "\n",
    "def get_html_and_save(url):\n",
    "    '''\n",
    "    Take a url for a web page get the html and store the text.\n",
    "    \n",
    "    return the name of the html and the name of file to save.\n",
    "    (Turns out `%store` magics didn't work in the function?!)\n",
    "    \n",
    "    based on https://stackoverflow.com/a/30890016/8508004\n",
    "    '''\n",
    "    hh = urllib.request.urlopen(url)\n",
    "    hbytes = hh.read()\n",
    "\n",
    "    the_html = hbytes.decode(\"utf8\")\n",
    "    #print (the_html[:200])\n",
    "    hh.close()\n",
    "    fn_save_name = extract_name_of_the_html(url, add_html_extension=False)\n",
    "    \n",
    "    #%store the_html > {fn_save_name} #seems cannot use this in a function?;\n",
    "    # probably because it needs to be a global and here it would be local\n",
    "    # variable it would be trying to save.\n",
    "    \n",
    "    return the_html,fn_save_name\n",
    "\n",
    "htmls_collected = []\n",
    "markdowns_made = []\n",
    "for url in urls_to_get:\n",
    "    the_html,fn_save_name = get_html_and_save(url)\n",
    "    %store the_html > {fn_save_name}\n",
    "    htmls_collected.append(fn_save_name)\n",
    "    markdown_name = fn_save_name.rsplit(\".html\")[0] + \".md\"\n",
    "    !pandoc -s -f html -t markdown {fn_save_name} -o {markdown_name}\n",
    "    sys.stderr.write(\"'{}' has been generated.\\n\".format(markdown_name))\n",
    "    markdowns_made.append(markdown_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterating over markdown produced and collect packages needed for running all R code\n",
    "--------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#markdowns_made = [\"d_06.md\"] # Uncomment for debugging only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_libraries_from_md(md):\n",
    "    '''\n",
    "    Go through markdown line by line and collect packages needed from lines like:\n",
    "    \n",
    "    if(!require(DescTools)){install.packages(\\\"DescTools\\\")}\\\n",
    "    if(!require(RVAideMemoire)){install.packages(\\\"RVAideMemoire\\\")}\\\n",
    "    \n",
    "    Return packages as list\n",
    "    '''\n",
    "    packages_needed = []\n",
    "    with open(md, 'r') as input:\n",
    "        for line in input:\n",
    "            if (line.strip().startswith(\"if(!require\")) and (\n",
    "                \"{install.packages(\" in line):\n",
    "                package_nom = line.split('{install.packages(')[1].split('\\\")}')[0].strip()\n",
    "                packages_needed.append(package_nom[2:-1])\n",
    "    return packages_needed\n",
    "\n",
    "R_packages = []\n",
    "for md in markdowns_made:\n",
    "    extracted_packages = extract_libraries_from_md(md)\n",
    "    R_packages += extracted_packages\n",
    "R_packages = list(set(R_packages))\n",
    "R_packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make the install.R file for the repository\n",
    "\n",
    "While doing this, address any peculiarites I have seen come up. For example, for `RVAideMemoire`, I've seen that simply including `install.packages(\"RVAideMemoire\")` won't result in an environment that allows it to run when launched via Binder. It reports that it needs `mixOmics` to work as well and it doesn't seem to get installed as `mixOmics` has been moved from CRAN / MRAN to Bioconductor. I found that it was then necessary to add in the special handling needed to get that in the `Install.R` file if `RVAideMemoire` is among the list of libraries required.\n",
    "\n",
    "install.packages(\"BiocManager\")\n",
    "BiocManager::install(\"mixOmics\")\n",
    "\n",
    "Nothing is needed in the `install.R` file for the package `agricolae`, but while talking about special handling necessary for `RVAideMemoire`, it probably is good place to point out special handling was needed to get the package `agricolae` to be useable. Because so much goes on when the image builds, I probably missed that `agricolae` was having issues but it became apparent installation failed when I tried to run notebooks that used it, like `d_06`, because `library(agricolae)` doesn't work even though it is listed in `installs.R`.  I thought maybe it is like the case of`RVAideMemoire` and needs some dependency specially handled and so I looked around. I found [this post](https://www.reddit.com/r/RStudio/comments/63hkje/cant_install_agricolae_package/) that suggested it wasn't working because needed gfortran?. Luckily, working on my getting David Goodsell's Illustrate script working in my pymol-binder, I learned how to install gfortran on Binder-launchable systems using `apt.txt` and so I could do that. As another avenue of learning about what might be the issue, I made a repo that only tried installing argicolae and tried then bringing it in the sessio with `library(agricolae)`, but it still failed. Didn't indicate what it needed there but when I tried `install.packages(\"agricolae\")` in the running session, I did see something about also installing some other dependencies  which I would have expected to already been installed since I had `install.packages(\"agricolae\")` in the `install.R` script included in the repo. The three listed were: ‘units’, ‘sf’, ‘spdep’. And then it said installation of each of those packages returned non-zero exit status. So I looked around about installing those libraries and found [this](https://philmikejones.me/tutorials/2018-08-29-install-sf-ubuntu/) about `units` and `sf`. And so I added the two listed for units to the list in `apt.txt` that I was making to include gfortran.\n",
    "Also found [this](https://r-spatial.github.io/sf/), which listed the four `libudunits2-dev libgdal-dev libgeos-dev libproj-dev`, and so I added the additional three listed there. (Already had `libudunits2-dev` from the listing I just had mentioned before.)\n",
    "Actually next time ran the building process, I noticed among the list of installing was `gdal-data` and so I so went back to https://philmikejones.me/tutorials/2018-08-29-install-sf-ubuntu/ and added `libgdal-dev` to the growing `apt.txt` file, too. Ran the launch with the new `apt.txt` file with gfortran and those other libraries and when it came up I tried `library(agricolae)`, and it worked. So the `apt.txt` has been added to the repo, too. I don't know if I needed all those I added to `apt.txt` (aside: later I did see [this](https://github.com/satijalab/seurat/issues/791) suggesting `robustbase` also needed gfortran and so probably good it is included), but at least it solved the issue and it works.\n",
    "\n",
    "There are some libraries that didn't feature in text like `if(!require(PACKAGE)){install.packages(\"PACKAGE\")}` at the top of pertinent notebooks and so they didn't get mined when I used that to find packages needed. So need to add:\n",
    "\n",
    "* robustbase\n",
    "* popbio\n",
    "* PerformanceAnalytics\n",
    "* nlstools\n",
    "\n",
    "Plus, thought I'd add a few additional popular packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_additions_needed_for_RVAideMemoire = '''\\\n",
    "install.packages(\"BiocManager\")\n",
    "BiocManager::install(\"mixOmics\")\n",
    "'''\n",
    "\n",
    "additions_for_additional_packages = '''install.packages(\"robustbase\")\n",
    "install.packages(\"popbio\")\n",
    "install.packages(\"PerformanceAnalytics\")\n",
    "install.packages(\"nlstools\")\n",
    "'''\n",
    "\n",
    "additional_popular_packages='''install.packages(\"tidyverse\")\n",
    "install.packages(\"rmarkdown\")\n",
    "install.packages(\"httr\")\n",
    "'''\n",
    "\n",
    "basic_line = 'install.packages(\"PLACEHOLDER\")'\n",
    "text_2_save = ''\n",
    "if \"RVAideMemoire\" in R_packages:\n",
    "        text_2_save += special_additions_needed_for_RVAideMemoire\n",
    "for x in R_packages:\n",
    "    text_2_save += basic_line.replace(\"PLACEHOLDER\",x)\n",
    "    text_2_save += \"\\n\"\n",
    "text_2_save += additions_for_additional_packages\n",
    "text_2_save += additional_popular_packages\n",
    "%store text_2_save > install.R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download `install.R` for placing in the repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
