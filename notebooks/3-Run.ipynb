{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Three\n",
    "\n",
    "Follows from `two`.\n",
    "\n",
    "Meant to be run in sessions launched from [here](https://github.com/fomightez/rcomp_testenv). \n",
    "\n",
    "This is to run all the notebooks so that content produced by code visible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP #1: Unpack previous results\n",
    "\n",
    "**REQUIRED FILES**\n",
    "\n",
    "Besides this notebook (and installed notedown packages) the following must be uploaded to the running binder session:\n",
    "\n",
    "- `unrun_notebooks_from_RCompanion.tar.gz` from `Two.ipynb` . This contains unrun notebooks I made for each of the pages plus three pertinent lists stored as json.\n",
    "\n",
    "Unpack that. And bring in the list of urls and files into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "unpacked_example = os.path.join(\".\",\"RCompanion_urls_to_get.json\")\n",
    "file_needed = \"unrun_notebooks_from_RCompanion.tar.gz\"\n",
    "\n",
    "import sys\n",
    "if os.path.isfile(unpacked_example):\n",
    "    sys.stderr.write(\"\\nAppears '{}' has already been unpacked.\\n\".format(file_needed))\n",
    "elif os.path.isfile(file_needed):\n",
    "    !tar xzf {file_needed}\n",
    "else:\n",
    "    sys.stderr.write(\"\\n\\n*****************ERROR**************************\\n\"\n",
    "        \"The file '{0}' is needed.\\n\"\n",
    "        \"Upload '{0}' to this Jupyter session and re-run this cell.\\n\"\n",
    "        \"*****************ERROR**************************\\n\".format(file_needed))\n",
    "    sys.exit(1)\n",
    "stored_json_files_and_names = [\n",
    "    \"RCompanion_markdowns_made.json\",\n",
    "    \"RCompanion_urls_to_get.json\",\n",
    "    'RCompanion_notebooks_made.json'\n",
    "                            ]\n",
    "stored_json_files_and_names_to_unpack_as = {k:f'{k.split(\"_\")[0]}_{k.split(\"_\")[1]}' for k in stored_json_files_and_names}\n",
    "import json\n",
    "for k,v in stored_json_files_and_names_to_unpack_as.items():\n",
    "    with open(k, 'r') as f:\n",
    "        globals()[v] = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP #2: Run each notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd rcomp_nbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' # THIS RUNS NOTEBOOKS WITHOUT HANDLING ANY ERRORS BUT REPORTS\n",
    "# THE ERRORS HERE.\n",
    "for nb in RCompanion_notebooks:\n",
    "    !jupyter nbconvert --to notebook --ExecutePreprocessor.kernel_name=ir --ExecutePreprocessor.timeout=300 --execute {nb} --output={nb}\n",
    "    sys.stderr.write(\"The notebook, {}, has been run\"\n",
    "        \".\\n\".format(nb))\n",
    "''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run notebooks with error handling so still run with R despite errors\n",
    "# and report errors here and in notebook, based on \n",
    "# https://nbconvert.readthedocs.io/en/latest/execute_api.html\n",
    "import nbformat\n",
    "from nbconvert.preprocessors import ExecutePreprocessor\n",
    "from nbconvert.preprocessors import CellExecutionError\n",
    "\n",
    "run_path = '.'\n",
    "ep = ExecutePreprocessor(timeout=300, kernel_name='ir')\n",
    "\n",
    "unindicated_kernel_str = '''\"metadata\": {}'''\n",
    "kernel_str = '''\"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"R\",\n",
    "   \"language\": \"R\",\n",
    "   \"name\": \"ir\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": \"r\",\n",
    "   \"file_extension\": \".r\",\n",
    "   \"mimetype\": \"text/x-r-source\",\n",
    "   \"name\": \"R\",\n",
    "   \"pygments_lexer\": \"r\",\n",
    "   \"version\": \"3.6.1\"\n",
    "  }\n",
    " }'''\n",
    "needs_kernel_set = []\n",
    "\n",
    "d_08_msg ='''If you are running notebook d_08, because of the way the \\\n",
    "`rcompanion` library throws an error if it encounters the result `No significant differences.`\\\n",
    ", see https://github.com/cran/rcompanion/blob/eaab0c944c4c1984707a84d9add4b9450a3bf390/R/cldList.r#L98 \\\n",
    "expect the following for the last cell in this notebook:\n",
    "An error occurred while executing the following cell:\n",
    "------------------\n",
    "### Extract lsmeans table\n",
    "Sum = PT$diffs.lsmeans.table\n",
    "\n",
    "\n",
    "### Extract comparisons and p-values\n",
    "  Comparison = rownames(Sum)\n",
    "\n",
    "P.value   = Sum$'p-value'\n",
    "\n",
    "\n",
    "### Adjust p-values\n",
    "P.value.adj = p.adjust(P.value,\n",
    "                       method =  \"none\")   \n",
    "\n",
    "### Fix names of comparisons\n",
    "Comparison = gsub(\"-\", \"- Day\", Comparison)\n",
    "\n",
    "\n",
    "### Produce compact letter display\n",
    "library(rcompanion)\n",
    "\n",
    "cldList(comparison = Comparison,\n",
    "        p.value    = P.value.adj,\n",
    "        threshold = 0.05)\n",
    "------------------\n",
    "\n",
    "Error: No significant differences.\n",
    "Traceback:\n",
    "\n",
    "1. cldList(comparison = Comparison, p.value = P.value.adj, threshold = 0.05)\n",
    "2. stop(\"No significant differences.\", call. = FALSE)\n",
    "ERROR: Error: No significant differences.\n",
    "'''\n",
    "\n",
    "for nb_fn in RCompanion_notebooks:\n",
    "    with open(nb_fn) as f:\n",
    "        nb = nbformat.read(f, as_version=4)\n",
    "    msg = 'Running the notebook \"%s\".\\n' % nb_fn\n",
    "    sys.stderr.write(msg)\n",
    "    if nb_fn == \"d_08.ipynb\":\n",
    "      sys.stderr.write(d_08_msg)\n",
    "    try:\n",
    "        out = ep.preprocess(nb, {'metadata': {'path': run_path}})\n",
    "    except CellExecutionError as e:\n",
    "        out = None\n",
    "        msg = 'Error executing the notebook \"%s\".\\n\\n' % nb_fn\n",
    "        #msg += 'See notebook \"%s\" for the traceback.' % nb_fn\n",
    "        print(\"Error info for {}:\\n\".format(nb_fn),e)\n",
    "        #raise\n",
    "        # Set up for adding the kernel information because those that stop\n",
    "        # without completion due to error, don't include that \n",
    "        needs_kernel_set.append(nb_fn)\n",
    "    finally:\n",
    "        with open(nb_fn, mode='w', encoding='utf-8') as f:\n",
    "            nbformat.write(nb, f)\n",
    "def rreplace(s, old, new, occurrence):\n",
    "  '''\n",
    "  string replace from right side. Like `rsplit` but for `str.replace()`.\n",
    "  from https://stackoverflow.com/a/2556252/8508004\n",
    "  '''\n",
    "  li = s.rsplit(old, occurrence)\n",
    "  return new.join(li)\n",
    "# fix so R is kernel for those not completed due to error being encountered\n",
    "for nb_fn in needs_kernel_set:\n",
    "    with open(nb_fn, 'r') as input:\n",
    "        nb_text=input.read()\n",
    "    nb_text = rreplace(nb_text,unindicated_kernel_str,kernel_str,1)\n",
    "    with open(nb_fn, mode='w', encoding='utf-8') as f:\n",
    "        f.write(nb_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now collect the notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the next cell to archive the run notebooks made from the content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_file_name = \"Rnotebooks_from_RCompanion.tar.gz\"\n",
    "import os\n",
    "import sys\n",
    "\n",
    "files_to_archive = RCompanion_notebooks\n",
    "!tar czf {archive_file_name} {\" \".join(files_to_archive)}\n",
    "%cd ..\n",
    "!cp rcomp_nbs/{archive_file_name} .\n",
    "sys.stderr.write(\"***************************DONE***********************************\\n\"\n",
    "    \"'{}' generated. Download it.\\n\"\n",
    "    \"***************************DONE***********************************\".format(archive_file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
